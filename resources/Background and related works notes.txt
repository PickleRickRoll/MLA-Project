Background and Related Work :

Automatic transcription of music (AMT) have three dimensions (1) The degree of output (Polyphony/Monophony) (2) the type of output (MPE, note-level) (3) the type of input.

A/ Concerning the degree of Output :

In our case we will be working in the polyphony case : Polyphony is having multiple pitches playing at the same time which could stem from multiple instruments or sometime only one.

B/ Concerning the type of output :

1/ Pitches and notes :
- Pitches are a way of defining "how high/low" is a sound, in a way it can be seen as a "volume", it is defined by it's harmonic frequency f0 and within a time frame.
- Notes are musical notes (duh), they are defined by asking "which note is played? for how long? at what pitch?" so they bring more information to a musician.


2/ frame-level multipitch estimation (MPE) and note-level estimation :
- MPE happens within a time frame, and the goal is to estimate each pitch (or it's frequency f0) separately from the others, so in a way we want to know what pitches are playing in that time frame.
- note-level estimation on the other hand aims to estimate the notes themselves, it is defined by an onset (start time), offset (end time) and the note itself.

**Many works aim to extract note estimations from MPE outputs, which cannot be directly done due to an MPE not having any information about the onset/offset and having fluctuation in pitches.

C/ Concerning the Input :

The aim is to have simple models that can be generalisable to various input instruments, however recent and more performant models are complex with high computational requirements that focus on a specific instrument.

